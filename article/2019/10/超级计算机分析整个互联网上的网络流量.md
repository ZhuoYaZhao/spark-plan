原文链接: https://news.mit.edu/2019/supercomputer-analyzes-web-traffic-across-entire-internet-1028 

原作者： Rob Matheson | 麻省理工学院新闻办公室 

翻译整理者：Qiang He  

---  
![捕获特定日期的全球Web流量](img/model.jpg)

### 超级计算机分析整个互联网上的网络流量

摘要:对网络流量进行建模可以帮助网络安全，计算基础架构设计，Internet策略等。 

时间: 2019年10月27日 

内容：麻省理工学院的研究人员使用超级计算系统开发了一个模型，该模型可以捕获特定日期世界各地的网络流量，可以将其用作互联网研究和许多其他应用程序的度量工具。

研究人员说，如此大规模地了解网络流量模式，有助于了解互联网政策，识别和防止中断，防御网络攻击以及设计更高效的计算基础架构。在最近的IEEE高性能极限计算会议上发表了一篇描述该方法的论文。

对于他们的工作，研究人员收集了最大的可公开访问的互联网流量数据集，其中包括在过去几年内在全球不同地点交换的500亿个数据包。

他们通过一个新的“神经网络”管道运行数据，该管道在MIT SuperCloud的10,000个处理器上运行，该系统结合了MIT林肯实验室和研究所的计算资源。该管道自动训练了一个模型，该模型捕获了数据集中所有链接的关系-从常见的ping到Google和Facebook之类的巨头，再到罕见的仅短暂连接但似乎对网络流量有影响的链接。  

该模型可以获取任何庞大的网络数据集，并生成一些有关网络中所有连接如何相互影响的统计度量。这可以用来揭示有关点对点文件共享、恶意IP地址和垃圾邮件行为、关键扇区中攻击的分布以及流量瓶颈的见解，以便更好地分配计算资源并保持数据流动。

从概念上讲，这项工作类似于测量宇宙微波背景，即围绕宇宙传播的几乎均匀的无线电波，这是研究外层空间现象的重要信息来源。麻省理工学院林肯实验室超级计算中心研究员、天文学家杰里米·凯普纳（Jeremy Kepner）说：“我们建立了一个精确的模型，用来测量互联网虚拟宇宙的背景。”如果要检测任何差异或异常，必须有一个良好的背景模型

与凯普纳一起发表论文的有：日本互联网倡议组织的赵健二郎，圣地亚哥加州大学应用互联网数据分析中心的kc克拉菲，林肯实验室超级计算中心的vijay gadepally和peter michaleas，麻省理工学院地球系的研究员lauren milechin，大气和行星科学。

**分解数据**

在互联网研究中，专家研究网络流量异常，这些异常可能表示例如网络威胁。为此，它有助于首先了解正常流量的情况。但是捕获这些仍然具有挑战性。传统的“流量分析”模型只能分析受位置限制的来源与目的地之间交换的数据包的小样本。这降低了模型的准确性。

研究人员并没有特别想解决这个流量分析问题。但是他们一直在开发可以在MIT SuperCloud上使用的新技术，以处理大量的网络矩阵。互联网流量是完美的测试案例。

网络通常以图的形式进行研究，参与者以节点表示，链接表示节点之间的连接。随着互联网流量的增加，节点的大小和位置也有所不同。大型超级节是流行的枢纽，例如Google或Facebook。叶节点从该超级节点展开，并且彼此之间以及与该超级节点具有多个连接。隔离节点和链接位于超级节点和叶节点的“核心”之外，它们之间很少连接。

捕获这些图的全部范围对于传统模型是不可行的。Kepner说：“如果没有超级计算机的访问，就无法触摸这些数据。”

麻省理工学院的研究人员与由几所日本大学建立的广泛集成分布式环境（WIDE）项目以及位于加利福尼亚的应用互联网数据分析中心（CAIDA）合作，捕获了全球最大的互联网流量数据包捕获数据集。匿名数据集可追溯到2015年，在日本和美国的不同地点，随机日期内，消费者与各种应用和服务之间包含近500亿个唯一的来源和目标数据点。

在他们根据该数据训练任何模型之前，他们需要进行一些广泛的预处理。为此，他们利用了他们先前创建的称为动态分布式维度数据模式（D4M）的软件，该软件使用一些平均技术来有效地计算和分类“超稀疏数据”，该数据包含比数据点更多的空白空间。研究人员将数据分解为10,000个MIT SuperCloud处理器中约100,000个数据包的单位。这产生了源与目的地之间数十亿行和列的交互的更紧凑矩阵。

**捕获异常值**

但是此稀疏数据集中的绝大多数单元仍然为空。为了处理矩阵，团队在相同的10,000个核上运行了神经网络。在幕后，反复试验技术开始将模型拟合到整个数据中，从而创建了潜在准确模型的概率分布。

然后，它使用改进的纠错技术进一步细化每个模型的参数，以捕获尽可能多的数据。传统上，机器学习中的纠错技术会试图降低任何外围数据的重要性，以使模型符合正态概率分布，从而使模型整体上更精确。但是研究人员使用了一些数学技巧来确保模型仍然看到所有外围数据（例如，隔离的链接）对整体测量而言都是重要的。

最后，神经网络本质上生成了一个仅包含两个参数的简单模型，该模型描述了互联网流量数据集，“从真正流行的节点到孤立的节点，以及介于两者之间的所有信息的完整频谱，” Kepner说。

现在，研究人员正在与科学界联系，以寻找该模型的下一个应用程序。例如，专家可以检查研究人员在实验中发现的孤立链接的重要性，这种链接很少，但似乎会影响核心节点中的网络流量。

除了互联网之外，神经网络管道还可用于分析任何超稀疏网络，例如生物和社会网络。开普纳说：“对于想要建立更强大的网络或检测网络异常的人们来说，我们现在为科学界提供了一个了不起的工具。” “这些异常可能只是用户行为的正常行为，也可能是人们在做您不想要的事情。”

**主题**：研究  EAPS  林肯实验室  科学学院计算机科学与技术   

​			算法   人工智能  机器学习   数据  超级计算   Internet 网络安全 

​	

​		
